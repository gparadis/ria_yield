{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('processing tsa', tsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ = f.loc[tsa].reset_index().set_index(stratum_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_nstrata = {'08':20, '16':50, '24':20, '40':20, '41':20}\n",
    "target_nstrata = {'08':9, '16':13, '24':8, '40':7, '41':10}\n",
    "\n",
    "#target_nstrata = {'08':2, '16':13, '24':13, '40':7, '41':7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalarea = f_.FEATURE_AREA_SQM.sum()\n",
    "f_['totalarea_p'] = f_.FEATURE_AREA_SQM / totalarea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile stats for top n strata (30)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_standcount = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strata_gb1 = f_.groupby(level=stratum_col)\n",
    "totalarea_p_sum = strata_gb1.totalarea_p.sum().nlargest(target_nstrata[tsa])\n",
    "largestn_strata_codes = list(totalarea_p_sum.index.values)\n",
    "strata_gb2 = f_.groupby(level=stratum_col)\n",
    "site_index_std = strata_gb2.SITE_INDEX.std()\n",
    "site_index_iqr = strata_gb2.SITE_INDEX.quantile(0.75) - strata_gb2.SITE_INDEX.quantile(0.25)\n",
    "site_index_median = strata_gb2.SITE_INDEX.median()\n",
    "stand_count = strata_gb2.FEATURE_ID.count()\n",
    "coverage = strata_gb2.totalarea_p.sum()\n",
    "crown_closure = strata_gb2.CROWN_CLOSURE.median()\n",
    "strata_df = pd.DataFrame(totalarea_p_sum)\n",
    "strata_df['site_index_std'] = site_index_std\n",
    "strata_df['site_index_iqr'] = site_index_iqr\n",
    "strata_df['site_index_median'] = site_index_median\n",
    "strata_df['stand_count'] = stand_count\n",
    "strata_df['coverage'] = coverage\n",
    "strata_df['crown_closure'] = crown_closure\n",
    "strata_df = strata_df[strata_df.stand_count >= min_standcount]\n",
    "strata_df = strata_df.head(target_nstrata[tsa])\n",
    "print('mean stratum SI IQR', site_index_iqr.mean())\n",
    "print('coverage', strata_df.coverage.sum())\n",
    "print('count', strata_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f__ = f_.loc[strata_df.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot histogram of media SI values in top n strata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = strata_df.site_index_median.hist(bins=np.arange(25, step=1))\n",
    "ax.set_xlim([0, 25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot scatter of stratum relative area coverage (x) versus SI (y) to confirm that there is no obvious correlation between stratum abundance and SI (so we can safely merge the small strata into the top n strata without high risk of inducing bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strata_df['median_si'] = f_[f_.index.isin(largestn_strata_codes)].groupby(level=stratum_col).SITE_INDEX.median()\n",
    "plt.scatter(strata_df.totalarea_p, strata_df.median_si)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot SI distribution and relative abundance by stratum for the top n strata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(8, 12)\n",
    "alpha = 0.2\n",
    "linewidth = 1.0\n",
    "inner = 'box'\n",
    "showfliers= False\n",
    "width = 0.8\n",
    "bw =  'scott'\n",
    "cut = 0\n",
    "\n",
    "sort_lex = 0\n",
    "if sort_lex:\n",
    "    stratum_props = list(strata_df.sort_index().totalarea_p.values)\n",
    "    labels = sorted(strata_df.sort_index().index.values)\n",
    "else: # sort by abundance\n",
    "    stratum_props = list(strata_df.totalarea_p.values)\n",
    "    labels = strata_df.index.values\n",
    "\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax2 = ax.twiny()\n",
    "sns.barplot(y=labels, x=stratum_props, ax=ax, alpha=alpha, label='Relative abundance of stratum (proportion of total area)')\n",
    "sns.violinplot(y=stratum_col, x='SITE_INDEX', data=f_.reset_index(), ax=ax2, bw=bw, order=labels, linewidth=linewidth, inner=inner, showfliers=showfliers, width=width, cut=cut, showextrema=False)\n",
    "#sns.violinplot(y=stratum_col, x='siteprod', data=f_.reset_index(), ax=ax2, bw=bw, order=labels, linewidth=linewidth, inner=inner, showfliers=showfliers, width=width, cut=cut, showextrema=False)\n",
    "ax.set_xlabel('Relative abundance of stratum (proportion of total area)')\n",
    "ax2.set_xlim([0, 30])\n",
    "plt.savefig('plots/strata-tsa%s.pdf' % tsa, bbox_inches='tight')\n",
    "plt.savefig('plots/strata-tsa%s.png' % tsa, facecolor='white', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match small strata to top n strata. We use Levenshtein distance to match augmented stratum codes to good candidates in the top n strata, and pick the biggest one if multiple matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1 = set(f_.loc[strata_df.index.values].stratum_lexmatch.unique())\n",
    "names2 = set(f_.stratum_lexmatch.unique()) - names1\n",
    "\n",
    "stratum_key = f_.reset_index().groupby('%s_lexmatch' % stratum_col)[stratum_col].first()\n",
    "totalarea_p_sum__ = f_.groupby('%s_lexmatch' % stratum_col).totalarea_p.sum()\n",
    "lev_dist = {n2:{n1:distance.levenshtein(n1, n2) for n1 in names1} for n2 in names2}\n",
    "lev_dist_low = {n2:{n1:(lev_dist[n2][n1], totalarea_p_sum__.loc[n1]) \n",
    "                    for n1 in lev_dist[n2].keys() if lev_dist[n2][n1] == min(lev_dist[n2].values())} \n",
    "                for n2 in names2}\n",
    "best_match = {stratum_key.loc[n2]:stratum_key[max(lev_dist_low[n2].items(), key=operator.itemgetter(1))[0]] for n2 in names2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_stratum(r):\n",
    "    return r[stratum_col] if r[stratum_col] in strata_df.index.values else best_match[r[stratum_col]]\n",
    "\n",
    "f_['%s_matched' % stratum_col] = f_.swifter.apply(match_stratum, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratum_col = '%s_matched' % stratum_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f__ = f_.set_index(stratum_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some fit functions which we will use later to smooth the wobbles out of the VDYP yield curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_func1(x, a, b, c, s):\n",
    "    return s * (a * ((x-c)**b)) * np.exp(-a * (x-c))\n",
    "    \n",
    "def fit_func1_bounds_func(x):\n",
    "    return ([0.000, 0, 0, 0], \n",
    "            [1.00, 50, max(1, min(np.min(x), 100)), 10])\n",
    "\n",
    "body_fit_func = fit_func1\n",
    "body_fit_func_bounds_func = fit_func1_bounds_func\n",
    "toe_fit_func = fit_func1\n",
    "toe_fit_func_bounds_func = fit_func1_bounds_func\n",
    "\n",
    "#def fit_func2(x, a, b, c, d, s):\n",
    "#    return s * (a * ((x-c)**b)) * np.exp(-(x-c) / d)\n",
    "\n",
    "#def fit_func2_bounds(x):\n",
    "#    return ([0.000, 0, 0, 0.01, 0], \n",
    "#            [1.00, 50, min(np.min(x), 100), 100, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratum_si_stats = f__.groupby(stratum_col).SITE_INDEX.agg(['mean', 'median', 'std', 'min', 'max', 'quantile', 'quantile'],\n",
    "                                                        [None, None, None, None, None, 0.25, 0.75])\n",
    "stratum_si_stats = f__.groupby(stratum_col).SITE_INDEX.describe(percentiles=[0, 0.05, 0.20, 0.35, 0.5, 0.65, 0.80, 0.95, 1])\n",
    "#stratum_si_stats = f_.groupby(stratum_col).siteprod.agg(['mean', 'median', 'std', 'min', 'max', 'quantile', 'quantile'],\n",
    "#                                                        [None, None, None, None, None, 0.25, 0.75])\n",
    "#stratum_si_stats = f_.groupby(stratum_col).siteprod.describe(percentiles=[0, 0.05, 0.20, 0.35, 0.5, 0.65, 0.80, 0.95, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_stratum(f_, fit_func, fit_func_bounds_func, strata_df, stratum_si_stats, stratumi, plot=True, figsize=(6, 12), \n",
    "                verbose=False, xlim=(0, 300), ylim=(0, 500),     \n",
    "                si_levelquants={'L':[5, 20, 35], 'M':[35, 50, 65], 'H':[65, 80, 95]},\n",
    "                linestyles=['-', '--', ':'], markers=['x', '+', '*'], palette_flavours=['RdPu', 'Blues', 'Greens'],\n",
    "                maxfev=100000, min_age=30, max_age=300, max_records=15000, sigma_exponent=1., window=10, min_periods=None, center=False, \n",
    "                agg_type='median', sv_thresh=0.10, rawdata_alpha=0.05, fitattr_thresh=1., fit_rawdata=True, debug=False):\n",
    "    #def fit_func(x, a, b, c, s):\n",
    "    #    return s * (a * ((x-c)**b)) * np.exp(-a * (x-c))\n",
    "    palettes = [sns.color_palette(pf, 3) for pf in palette_flavours]\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    sc = strata_df.iloc[stratumi].name\n",
    "    if verbose:\n",
    "        print('processing stratum', sc)\n",
    "    si_popt = {}\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(4, 1, figsize=figsize, sharex=True, sharey=True)\n",
    "        palette = sns.color_palette(\"RdPu\", 3)\n",
    "        sns.set_palette(palette)\n",
    "        ax_ = {}\n",
    "        ax_['L'], ax_['M'], ax_['H'] = ax[1], ax[2], ax[3]\n",
    "        palette_ = {v:palette[i] for i, v in enumerate('LMH')}\n",
    "    result = {}\n",
    "    for i, (si_level, Q) in enumerate(si_levelquants.items()):\n",
    "        result[si_level] = {}\n",
    "        ss = f_.loc[sc]\n",
    "        si_lo = stratum_si_stats.loc[sc].loc['%i%%' % Q[0]]\n",
    "        si_md = stratum_si_stats.loc[sc].loc['%i%%' % Q[1]]\n",
    "        si_hi = stratum_si_stats.loc[sc].loc['%i%%' % Q[2]] \n",
    "        ss = ss[(ss.SITE_INDEX >= si_lo) & (ss.SITE_INDEX < si_hi) & (ss.PROJ_AGE_1 >= min_age) & (ss.PROJ_AGE_1 < max_age)]\n",
    "        #ss = ss[(ss.siteprod >= si_lo) & (ss.siteprod < si_hi) & (ss.PROJ_AGE_1 >= min_age) & (ss.PROJ_AGE_1 < max_age)]\n",
    "        ss = ss.sort_values('PROJ_AGE_1')\n",
    "        sv = pd.Series({species:(ss['live_vol_per_ha_125_%s' % species].sum() / ss['LIVE_STAND_VOLUME_125'].sum())  \n",
    "                                 for species in species_list}).sort_values(ascending=False)\n",
    "        sv = sv[sv > sv_thresh]\n",
    "        #print(type(ss))\n",
    "        #assert type(ss) == pd.DataFrame\n",
    "        result[si_level]['ss'] = ss\n",
    "        if verbose:\n",
    "            print('sv sum', sv.sum())\n",
    "        if plot:\n",
    "            x, y = [], []\n",
    "            for j, species in enumerate(sv.index.values):\n",
    "                fitattr = 'live_vol_per_ha_125_%s' % species\n",
    "                sss = ss[ss[fitattr] >= 1]\n",
    "                x.append(sss.PROJ_AGE_1.values)\n",
    "                y.append(sss[fitattr].values / sv.sum())\n",
    "            x = np.concatenate(x)\n",
    "            y = np.concatenate(y)\n",
    "            ax_[si_level].scatter(x, y, alpha=rawdata_alpha, label='Raw data (%s SI, %s)' % (si_level, species), color='grey', marker=markers[j])\n",
    "        result[si_level]['species'] = {}\n",
    "        for j, species in enumerate(sv.index.values):\n",
    "            if verbose:\n",
    "                print('  fitting SI level %s (%2.1f), species %s' % (si_level, si_md, species))\n",
    "            fitattr = 'live_vol_per_ha_125_%s' % species\n",
    "            sss = ss[ss[fitattr] >= fitattr_thresh]\n",
    "            if fit_rawdata:\n",
    "                x = sss.PROJ_AGE_1.values\n",
    "                y = sss[fitattr].values / sv.sum()\n",
    "                sigma=None\n",
    "                agg = None\n",
    "            else: # fit smoothed data\n",
    "                agg = sss.groupby('PROJ_AGE_1')[fitattr].agg(['mean', 'median', 'std', 'count'])\n",
    "                agg = agg[agg['count'] > 2]\n",
    "                agg['sigma'] = ((agg['std'].mean() + agg['std']) / agg['count'])**0.5\n",
    "                x = agg.index.values\n",
    "                y = agg[agg_type].values / sv.sum()\n",
    "                sigma = agg['sigma'].values\n",
    "            #fit_func_bounds = ([0.000, 0, 0, 0], \n",
    "            #                   [0.100, 3, min(np.min(x), 100), 1000])\n",
    "            bounds = fit_func_bounds_func(x)\n",
    "            try:\n",
    "                popt, pcov = curve_fit(fit_func, x, y, bounds=bounds, maxfev=maxfev, sigma=sigma)\n",
    "            except:\n",
    "                print('error')\n",
    "                return x, y, sigma, agg\n",
    "\n",
    "            if verbose:\n",
    "                print('fitting N raw data points', sss.shape[0])\n",
    "                print('popt', popt)\n",
    "            if plot:\n",
    "                if not fit_rawdata:\n",
    "                    ax_[si_level].scatter(x, y, alpha=0.8, label='Smoothed data (%s SI, %s)' % (si_level, species), color='black', marker=markers[j])\n",
    "                x_ = np.linspace(popt[2], 300, 30)\n",
    "                y_ = fit_func(x_, *popt)\n",
    "                sns.lineplot(x_, y_, label='func fit (%s SI, %s)' % (si_level, species), ax=ax[0], color=palette_[si_level], linestyle=linestyles[j], linewidth=3)    \n",
    "                sns.lineplot(x_, y_, label='func fit (%s SI, %s)' % (si_level, species), ax=ax_[si_level], color=palette_[si_level], linestyle=linestyles[j], linewidth=3)\n",
    "            result[si_level]['species'][species] = {}\n",
    "            result[si_level]['species'][species]['si'] = si_md\n",
    "            result[si_level]['species'][species]['pct'] = int(round(100 * sv[species] / sv.sum()))\n",
    "            age = int(round(np.min(x) * 1.0))\n",
    "            #age = 100\n",
    "            result[si_level]['species'][species]['age'] = age if not np.isnan(age) else None\n",
    "            jj = min(2, j+1)\n",
    "            ssss = sss[(sss['PROJ_AGE_%i' % jj] >= age-5) & (sss['PROJ_AGE_%i' % jj] < age+5)]\n",
    "            height = ssss['PROJ_HEIGHT_%i' % jj].median()\n",
    "            result[si_level]['species'][species]['height'] = height if not np.isnan(height) else None\n",
    "            result[si_level]['species'][species]['fit_func'] = fit_func\n",
    "            result[si_level]['species'][species]['popt'] = popt\n",
    "            result[si_level]['species'][species]['pcov'] = pcov\n",
    "    if plot:\n",
    "        ax[0].set_title('Best-fit yield curves (stratum %s)' % sc)\n",
    "        plt.legend(loc='best')\n",
    "        plt.xlim(xlim)\n",
    "        plt.ylim(ylim)    \n",
    "        plt.xlabel('Stand age (years)')\n",
    "        plt.ylabel('Merch. volume (m3/ha)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('plots/yieldcurve_fit-%s-%s.png' % (str(stratumi).zfill(2), sc), facecolor='white')    \n",
    "        plt.savefig('plots/yieldcurve_fit-%s-%s.pdf' % (str(stratumi).zfill(2), sc), facecolor='white')    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile strata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30\n",
    "figsize = (8, 16)\n",
    "\n",
    "debug = 0\n",
    "fit_rawdata = 1\n",
    "min_age = 30\n",
    "agg_type = 'median'\n",
    "verbose = False\n",
    "plot = False\n",
    "\n",
    "results[tsa] = []\n",
    "for stratumi, sc in enumerate(strata_df.index.values[:]):\n",
    "    print('compiling stratum %s' % sc)\n",
    "    fit_out = fit_stratum(f__, body_fit_func, body_fit_func_bounds_func, strata_df, stratum_si_stats, stratumi, \n",
    "                      fit_rawdata=fit_rawdata, min_age=min_age, agg_type=agg_type,\n",
    "                      plot=plot, figsize=figsize, verbose=verbose, ylim=[0, 600], xlim=[0, 400])\n",
    "    results[tsa].append([stratumi, sc, fit_out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to create out VDYP input files from VDYP polygon and layer datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_vdyp_infiles_plylyr(feature_ids, vdyp_ply, vdyp_lyr, vdyp_io_dirname='vdyp_io', \n",
    "                              vdyp_ply_csv='vdyp_ply.csv', vdyp_lyr_csv='vdyp_lyr.csv'):\n",
    "    vdyp_ply_ = vdyp_ply[vdyp_ply.FEATURE_ID.isin(feature_ids)]\n",
    "    vdyp_ply_.sort_values(by='FEATURE_ID', inplace=True)\n",
    "    vdyp_ply_.to_csv('%s/%s' % (vdyp_io_dirname, vdyp_ply_csv), columns=list(vdyp_ply.columns)[:-5], index=False, quoting=csv.QUOTE_NONNUMERIC)\n",
    "    vdyp_lyr_ = vdyp_lyr[vdyp_lyr.FEATURE_ID.isin(vdyp_ply_.FEATURE_ID)]\n",
    "    vdyp_lyr_.sort_values(by='FEATURE_ID', inplace=True)\n",
    "    vdyp_lyr_.to_csv('%s/%s' % (vdyp_io_dirname, vdyp_lyr_csv), columns=list(vdyp_lyr.columns)[:-5], index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to read and parse VDYP output files (returns a list of dataframes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_vdyp_tables(filename):\n",
    "    import re, io\n",
    "    chunks = re.findall(r'(?<=vvvvvvvvvv.).*?(?=\\^)', open(filename).read(), re.DOTALL)\n",
    "    result = {}\n",
    "    for chunk in chunks:\n",
    "        lines = chunk.split('\\n')\n",
    "        polygon_id = int(re.search(r'(?<=Polygon:.)\\d+', lines[0]).group())\n",
    "        result_ = pd.read_fwf(io.StringIO(chunk), skiprows=[0, 2], index_col='Age', infer_nrows=200)\n",
    "        if type(result_) == pd.core.frame.DataFrame:\n",
    "            result[polygon_id] = result_\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to estimate the VRI polygon sample size required to estimate yield within MOE target window (at optimal rotation age)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nsamples_from_curves(vdyp_out, col='Vdwb', fit_func=body_fit_func, fit_func_bounds_func=body_fit_func_bounds_func, maxfev=10000,\n",
    "                         confidence=95, half_rel_ci=0.01, window=30, min_samples=10, max_samples=1000):\n",
    "    if len(vdyp_out) < min_samples: return np.inf\n",
    "    global xxx\n",
    "\n",
    "    z = {95:1.96}[confidence]\n",
    "    try:\n",
    "        vdyp_out_concat = pd.concat([v for v in vdyp_out.values() if type(v) == pd.core.frame.DataFrame])\n",
    "    except:\n",
    "        xxx = vdyp_out\n",
    "        assert False\n",
    "    c = vdyp_out_concat.groupby(level='Age')[col].median()\n",
    "    c = c[c > 0]\n",
    "    c = c[c.index >= 30]\n",
    "    x = c.index.values\n",
    "    y = c.rolling(window=window).median().values\n",
    "    x, y = x[y > 0], y[y > 0]  \n",
    "    popt, pcov = curve_fit(fit_func, x, y, bounds=fit_func_bounds_func(x), maxfev=maxfev)\n",
    "    y_ = fit_func(x, *popt)\n",
    "    y_mai = pd.Series(y_ / x, x)\n",
    "    y_mai_max_age = y_mai.idxmax()\n",
    "    sigma = vdyp_out_concat.groupby(level='Age')[col].std().loc[y_mai_max_age]\n",
    "    moe = c.loc[y_mai_max_age] * half_rel_ci * 2\n",
    "    nsamples = min(int((z * sigma / moe)**2) + 1, max_samples) if not np.isnan(sigma) else max_samples\n",
    "    return nsamples, (y_mai_max_age, c.loc[y_mai_max_age], moe, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to run VDYP. Uses wine to run VDYP on an Ubuntu linux server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vdyp(s, vdyp_ply, vdyp_lyr, vdyp_io_dirname='vdyp_io', \n",
    "             vdyp_outfile='ConsoleOutput.txt', vdyp_params_infile='vdyp_params-landp',\n",
    "             nsamples='auto', vdyp_binpath='VDYP7/VDYP7Console.exe',\n",
    "             si_levels=['L', 'M', 'H'], nsamples_c1=0.01, nsamples_c2=0.1, verbose=False, \n",
    "             confidence=95, half_rel_ci=0.05, min_samples=100, max_samples=640, ipp_mode=None, delete=True,\n",
    "             vdyp_timeout=2., vdyp_out_cache=None):\n",
    "    import subprocess\n",
    "    import shlex\n",
    "    global xxx\n",
    "    vdyp_output_path = '%s/%s' % (vdyp_io_dirname, vdyp_outfile)\n",
    "    def _run_vdyp(feature_ids, vdyp_io_dirname='vdyp_io', timeout=None): \n",
    "        import tempfile\n",
    "        vdyp_ply_csv_ = tempfile.NamedTemporaryFile(dir=vdyp_io_dirname, delete=delete)\n",
    "        vdyp_lyr_csv_ = tempfile.NamedTemporaryFile(dir=vdyp_io_dirname, delete=delete)\n",
    "        vdyp_out_txt_ = tempfile.NamedTemporaryFile(dir=vdyp_io_dirname, delete=delete)\n",
    "        vdyp_err_txt_ = tempfile.NamedTemporaryFile(dir=vdyp_io_dirname, delete=delete)\n",
    "        vdyp_ply_csv = vdyp_ply_csv_.name.split('/')[-1]\n",
    "        vdyp_lyr_csv = vdyp_lyr_csv_.name.split('/')[-1]\n",
    "        vdyp_out_txt = vdyp_out_txt_.name.split('/')[-1]\n",
    "        vdyp_err_txt = vdyp_err_txt_.name.split('/')[-1]\n",
    "        write_vdyp_infiles_plylyr(feature_ids, vdyp_ply, vdyp_lyr, \n",
    "                                  vdyp_io_dirname, vdyp_ply_csv, vdyp_lyr_csv)\n",
    "        args = 'wine %s -p %s -ip .\\\\\\\\%s\\\\\\\\%s -il .\\\\\\\\%s\\\\\\\\%s' % (vdyp_binpath,\n",
    "                                                                      vdyp_params_infile,\n",
    "                                                                      vdyp_io_dirname, vdyp_ply_csv,\n",
    "                                                                      vdyp_io_dirname, vdyp_lyr_csv)\n",
    "        args += ' -o .\\\\\\\\%s\\\\\\\\%s -e .\\\\\\\\%s\\\\\\\\%s' % (vdyp_io_dirname, vdyp_out_txt, \n",
    "                                                        vdyp_io_dirname, vdyp_err_txt)\n",
    "        try:\n",
    "            subprocess.run(shlex.split(args), timeout=timeout)\n",
    "        except:\n",
    "            return {}\n",
    "        vdyp_out = import_vdyp_tables('./%s/%s' % (vdyp_io_dirname, vdyp_out_txt))           \n",
    "        vdyp_ply_csv_.close()\n",
    "        vdyp_lyr_csv_.close()\n",
    "        vdyp_out_txt_.close()\n",
    "        vdyp_err_txt_.close()\n",
    "        return vdyp_out\n",
    "            \n",
    "    if nsamples == 'auto' and s.shape[0] >= min_samples: # automatically determine sample size\n",
    "        ss = s.reset_index().set_index('index')\n",
    "        samples = ss.sample(min(min_samples, ss.shape[0]))\n",
    "        feature_ids = samples.FEATURE_ID.values\n",
    "        vdyp_out = {}\n",
    "        if vdyp_out_cache is not None:\n",
    "            feature_ids_ = []\n",
    "            for fid in feature_ids:\n",
    "                if fid in vdyp_out_cache:\n",
    "                    vdyp_out[fid] = vdyp_out_cache[fid]\n",
    "                else:\n",
    "                    feature_ids_.append(fid)\n",
    "            feature_ids = feature_ids_\n",
    "        vdyp_out = _run_vdyp(feature_ids)\n",
    "        if vdyp_out_cache is not None: \n",
    "            vdyp_out_cache.update(vdyp_out)\n",
    "        ss.drop(samples.index, inplace=True)        \n",
    "        nsamples_target, _ = nsamples_from_curves(vdyp_out, confidence=confidence, half_rel_ci=half_rel_ci)\n",
    "        nsamples_target = min(max(nsamples_target, min_samples), ss.shape[0])\n",
    "        nsamples_gap = nsamples_target - len(vdyp_out)\n",
    "        nsamples_gap_rel = nsamples_gap / nsamples_target\n",
    "        while nsamples_gap_rel > nsamples_c1 and ss.shape[0]:\n",
    "            if nsamples_gap_rel > nsamples_c2:\n",
    "                nsamples_new = int(nsamples_gap * (1 - nsamples_gap_rel))  \n",
    "            else:\n",
    "                nsamples_new = nsamples_gap\n",
    "            nsamples_new = min(nsamples_new, max_samples, ss.shape[0])\n",
    "            if verbose: print('moe loop', nsamples_target, nsamples_new, '%0.2f' % nsamples_gap_rel, len(vdyp_out), ss.shape[0])\n",
    "            samples = ss.sample(nsamples_new)\n",
    "            feature_ids = samples.FEATURE_ID.values\n",
    "            timeout = 30 + (vdyp_timeout * feature_ids.shape[0] / len(rc))\n",
    "            if not ipp_mode or samples.shape[0] < min_samples:\n",
    "                if vdyp_out_cache is not None:\n",
    "                    feature_ids_ = []\n",
    "                    for fid in feature_ids:\n",
    "                        if fid in vdyp_out_cache:\n",
    "                            vdyp_out[fid] = vdyp_out_cache[fid]\n",
    "                        else:\n",
    "                            feature_ids_.append(fid)\n",
    "                    feature_ids = feature_ids_\n",
    "                vdyp_out_ = _run_vdyp(feature_ids, timeout=timeout)\n",
    "                vdyp_out.update(vdyp_out_)\n",
    "                if vdyp_out_cache is not None: \n",
    "                    vdyp_out_cache.update(vdyp_out)\n",
    "            elif ipp_mode == 'load_balanced':\n",
    "                assert False # not working... do not use this \n",
    "                print(' ipp start', feature_ids.shape[0])\n",
    "                amr = lv.map(_run_vdyp, np.array_split(feature_ids, len(rc)), ordered=False)\n",
    "                print(' ipp done')\n",
    "                try:\n",
    "                    amr.wait(timeout=timeout)\n",
    "                    for chunk in amr:\n",
    "                        vdyp_out.update(chunk)                \n",
    "                except:\n",
    "                    for msg_id in amr.msg_ids:\n",
    "                        try:\n",
    "                            chunk_amr = rc.get_result(msg_id)\n",
    "                            chunk = chunk_amr.get()\n",
    "                            vdyp_out.update(chunk)\n",
    "                        except:\n",
    "                            print('failed chunk', msg_id)\n",
    "            ss.drop(samples.index, inplace=True)\n",
    "            nsamples_target, _ = nsamples_from_curves(vdyp_out, confidence=confidence, half_rel_ci=half_rel_ci)\n",
    "            nsamples_target = min(max(nsamples_target, min_samples), s.shape[0])\n",
    "            nsamples_gap = nsamples_target - len(vdyp_out)\n",
    "            nsamples_gap_rel = nsamples_gap / nsamples_target\n",
    "        if verbose: print('final gap', nsamples_gap_rel)\n",
    "    elif nsamples == 'all':\n",
    "        vdyp_out = _run_vdyp(s.FEATURE_ID.values)\n",
    "    elif isinstance(nsamples, int):\n",
    "        samples = s.sample(nsamples)\n",
    "        feature_ids = samples.FEATURE_ID.values\n",
    "        vdyp_out = _run_vdyp(feature_ids)\n",
    "    else:\n",
    "        assert False # bad nsamples value\n",
    "    return vdyp_out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load _VDYP polygon_ VRI dataset (layer 0 in _VDYP poly and layer_ File Geodatabase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not os.path.isfile(vdyp_ply_feather_path):\n",
    "if 0:\n",
    "    vdyp_ply = gpd.read_file(vdyp_input_pandl_path, driver='FileGDB', layer=0)\n",
    "    vdyp_ply.to_feather(vdyp_ply_feather_path)\n",
    "else:\n",
    "    vdyp_ply = gpd.read_feather(vdyp_ply_feather_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load _VDYP layer_ VRI dataset (layer 1 in _VDYP poly and layer_ File Geodatabase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not os.path.isfile(vdyp_lyr_feather_path):\n",
    "if 0:\n",
    "    vdyp_lyr = gpd.read_file(vdyp_input_pandl_path, driver='FileGDB', layer=1)\n",
    "    vdyp_lyr.to_feather(vdyp_lyr_feather_path)\n",
    "else:\n",
    "    vdyp_lyr = gpd.read_feather(vdyp_lyr_feather_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over the strata and run VDYP, using the bootstrap sampling functions achieve MOE target to minimize the number of polygons that need to be run for each stratum. We run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdyp_results_tsa_pickle_path = '%s%s.pkl' % (vdyp_results_tsa_pickle_path_prefix, tsa)\n",
    "if not os.path.isfile(vdyp_results_tsa_pickle_path) or force_run_vdyp:\n",
    "    print()\n",
    "    vdyp_results[tsa] = {}\n",
    "    si_levels = ['L', 'M', 'H']\n",
    "    half_rel_ci = 0.01 # use 0.01 for production\n",
    "    si_levels_ = si_levels\n",
    "    ipp_mode = None\n",
    "    nsamples_c1 = 0.05\n",
    "    for stratumi, sc, result in results[tsa][:]:\n",
    "        vdyp_results[tsa][stratumi] = {}\n",
    "        for si_level in si_levels_:\n",
    "            print('running VDYP in bootstrap sample mode (%s, %s)' % (sc, si_level))\n",
    "            vdyp_out = run_vdyp(result[si_level]['ss'], vdyp_ply, vdyp_lyr, verbose=True, \n",
    "                                half_rel_ci=half_rel_ci, ipp_mode=ipp_mode, nsamples_c1=nsamples_c1, \n",
    "                                vdyp_out_cache=vdyp_out_cache)\n",
    "            vdyp_results[tsa][stratumi][si_level] = vdyp_out\n",
    "            print()\n",
    "    pickle.dump(vdyp_results[tsa], open(vdyp_results_tsa_pickle_path, 'wb'))\n",
    "else:\n",
    "    vdyp_results[tsa] = pickle.load(open(vdyp_results_tsa_pickle_path, 'rb'))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some new functions we will use below to smooth aggregated VDYP output for each stratum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@wraps(_curve_fit)\n",
    "def curve_fit(*args, **kwargs):\n",
    "    b = kwargs['bounds'] if 'bounds' in kwargs else None \n",
    "    if b and np.any(np.isfinite(b)) and 'max_nfev' not in kwargs:\n",
    "        kwargs['max_nfev'] = kwargs.pop('maxfev', None)\n",
    "    return _curve_fit(*args, **kwargs)\n",
    "\n",
    "#def toe_fit_func(x, a, b, c):\n",
    "#    return a*pow(x, b)\n",
    "\n",
    "def fit_func2(x, a, b):\n",
    "    return a * pow(x, b) * pow(x, -a)\n",
    "\n",
    "def fit_func2_bounds_func(x):\n",
    "    return (0, 0), (10, 10)\n",
    "\n",
    "def fill_curve_left(x, y, \n",
    "                    toe_fit_func=toe_fit_func, toe_fit_func_bounds_func=toe_fit_func_bounds_func,\n",
    "                    maxfev=10000, transpose_df=True, force_origin=True, skip=10, dx=0, di=20, cy=0.1):\n",
    "    x_, y_ = x, y\n",
    "    i1 = np.argmax(y_ > 0.)  \n",
    "    x__ = np.concatenate(([1+dx, 2+dx, 3+dx], x_[i1+skip:i1+skip+di]))\n",
    "    y__ = np.concatenate(([1*cy, 2*cy, 3*cy], y_[i1+skip:i1+skip+di]))\n",
    "    bounds = toe_fit_func_bounds_func(x__)\n",
    "    popt, _ = curve_fit(toe_fit_func, x__, y__, maxfev=maxfev, bounds=bounds)\n",
    "    y_[:i1+skip] = toe_fit_func(x_[:i1+skip], *popt)\n",
    "    return x_, y_, (i1+skip, popt)\n",
    "\n",
    "def plot_smoothed_toe(x, y, verbose=False, force_origin=True, skijump_skip=15):\n",
    "    x_, y_, i1, popt = fill_curve_left(testf1, x, y, force_origin=force_origin, skijump_skip=skijump_skip)\n",
    "    #return x_, y_, popt\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    plt.plot(x_, y_, linestyle='--', color='b')\n",
    "    plt.plot(x_[i1:], y_[i1:], linewidth=2, color='r')\n",
    "    plt.xlim([0, 300])\n",
    "    plt.ylim([0, 600])\n",
    "    if verbose: print(popt)\n",
    "    return fig, ax\n",
    "\n",
    "def process_vdyp_out(vdyp_out, volume_flavour='Vdwb', min_age=30, max_age=300, \n",
    "                     sigma_c1=10, sigma_c2=0.4, dx_c1=0.5, dx_c2=10,\n",
    "                     window=10,  skip1=0, skip2=30, maxfev=100000,\n",
    "                     body_fit_func=body_fit_func, body_fit_func_bounds_func=body_fit_func_bounds_func,\n",
    "                     toe_fit_func=toe_fit_func, toe_fit_func_bounds_func=toe_fit_func_bounds_func):\n",
    "    vdyp_out_concat = pd.concat([v for v in vdyp_out.values() if type(v) == pd.core.frame.DataFrame])\n",
    "    c = vdyp_out_concat.groupby(level='Age')[volume_flavour].median()\n",
    "    c = c[c > 0]\n",
    "    c = c[c.index >= min_age]\n",
    "    x = c.index.values\n",
    "    y = c.rolling(window=window, center=True).median().values\n",
    "    x, y = x[y > 0], y[y > 0]\n",
    "    x, y = x[skip1:], y[skip1:]\n",
    "    #return x, y\n",
    "    y_mai = pd.Series(y / x, x)\n",
    "    y_mai_max_age = y_mai.idxmax()\n",
    "    sigma = (np.abs(x - y_mai_max_age) + sigma_c1)**sigma_c2\n",
    "    popt, pcov = curve_fit(body_fit_func, x, y, bounds=body_fit_func_bounds_func(x), maxfev=maxfev, sigma=sigma)\n",
    "    x = np.array(range(1, max_age))\n",
    "    y = fit_func1(x, *popt)\n",
    "    dx = max(0, dx_c1 * popt[2] - dx_c2)\n",
    "    print(dx)\n",
    "    x, y, (i1, popt_toe) = fill_curve_left(x, y, skip=skip2, dx=dx, maxfev=maxfev,\n",
    "                                           toe_fit_func=toe_fit_func, toe_fit_func_bounds_func=toe_fit_func_bounds_func)\n",
    "    print(popt_toe)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kwarg_overrides = {'08':{('BWBS_SB', 'M'):{'skip1':30},\n",
    "#                         ('BWBS_SB', 'H'):{}},\n",
    "#                   '16':{('SWB_DE_BL', 'L'):{'skip2':0},\n",
    "#                         ('SWB_SP_BL', 'L'):{'skip1':30, 'skip2':0}},\n",
    "#                   '24':{('SBS_SP_SB', 'L'):{'skip1':50}},\n",
    "#                   '40':{},\n",
    "#                   '41':{('ESSF_SP_BL', 'L'):{'skip1':50}}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdyp_curves_smooth_tsa_feather_path = '%s%s.feather' % (vdyp_curves_smooth_tsa_feather_path_prefix, tsa)\n",
    "#if not os.path.isfile(vdyp_curves_smooth_tsa_feather_path):\n",
    "if 1:\n",
    "    figsize = (8, 6)\n",
    "    plot = 1\n",
    "    vdyp_smoothxy = {}\n",
    "    palette_flavours=['RdPu', 'Blues', 'Greens', 'Greys']\n",
    "    palette = sns.color_palette('Greens', 3)\n",
    "    sns.set_palette(palette)\n",
    "    alphas = [1.0, 0.5, 0.1]\n",
    "    for stratumi, sc, result in results[tsa]:\n",
    "        #if stratumi != 10: continue\n",
    "        if plot: fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "        print('stratum',stratumi, sc)\n",
    "        for i, si_level in enumerate(si_levels):\n",
    "        #for i, si_level in enumerate(['H']):            \n",
    "            print('processing', sc, si_level)\n",
    "            vdyp_out = vdyp_results[tsa][stratumi][si_level]\n",
    "            kwargs = {}\n",
    "            if (sc, si_level) in kwarg_overrides[tsa]:\n",
    "                kwargs.update(kwarg_overrides[tsa][(sc, si_level)])\n",
    "            x, y = process_vdyp_out(vdyp_out, **kwargs)\n",
    "            df = pd.DataFrame(zip(x, y), columns=['age', 'volume'])\n",
    "            df = df[df.volume > 0]\n",
    "            df['stratum_code'] = sc\n",
    "            df['si_level'] = si_level\n",
    "            vdyp_smoothxy[(sc, si_level)] = df \n",
    "            if plot:\n",
    "                vdyp_out_concat = pd.concat([v for v in vdyp_out.values() if type(v) == pd.core.frame.DataFrame])\n",
    "                c = vdyp_out_concat.groupby(level='Age')['Vdwb'].median()\n",
    "                c = c[c > 0]\n",
    "                c = c[c.index >= 30]\n",
    "                x_ = c.index.values\n",
    "                y_ = c.values\n",
    "                plt.plot(x_, y_, linestyle=':', label='VDYP->agg (%s %s)' % (sc, si_level), \n",
    "                         linewidth=2, color=palette[i])\n",
    "                plt.plot(x, y, label='%s %s' % (sc, si_level))\n",
    "        if plot: \n",
    "            plt.legend()\n",
    "            plt.xlim([0, 300])\n",
    "            plt.ylim([0, 600])\n",
    "            plt.tight_layout()\n",
    "    vdyp_curves_smooth[tsa] = pd.concat(vdyp_smoothxy.values()).reset_index()#.set_index(['stratum_code', 'si_level'])\n",
    "    vdyp_curves_smooth[tsa].to_feather(vdyp_curves_smooth_tsa_feather_path)\n",
    "#else:\n",
    "#    vdyp_curves_smooth[tsa] = pd.read_feather(vdyp_curves_smooth_tsa_feather_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIPSY yield curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we define AUs that should be modelled in TIPSY for each TSA, and compile the TISPY input parameter sets for each AU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define TSA-wise TIPSY AU exclusion criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_spruce = ['S', 'SB', 'SE', 'SN', 'SS', 'SW', 'SX', 'SXE', 'SXL', 'SXW']\n",
    "species_pine = ['P', 'PA', 'PJ', 'PL', 'PLC', 'PLI', 'PM']\n",
    "species_fir = ['B', 'BA', 'BB', 'BG', 'BL', 'BM', 'BP']\n",
    "species_larch = ['L', 'LA', 'LS', 'LT', 'LW']\n",
    "species_cedar = ['C', 'CW']\n",
    "species_hemlock = ['HM', 'HWI', 'HW']\n",
    "species_douglasfir = ['F', 'FD', 'FDC', 'FDI']\n",
    "\n",
    "species_aspen = ['AC', 'ACB', 'ACT', 'AD', 'AT', 'AX']\n",
    "species_birch = ['E', 'EA', 'EB', 'EE', 'EP', 'EW', 'EXP']\n",
    "species_willow = ['W','WA', 'WB', 'WD', 'WP', 'WS']\n",
    "species_alder = ['D', 'DR']\n",
    "species_cherry = ['V']\n",
    "species_dogwood = ['GP']\n",
    "species_oak = ['Q']\n",
    "species_maple = ['M', 'MB', 'MV']\n",
    "\n",
    "def tipsy_minsi_tsa08(leading_species):\n",
    "    if leading_species in species_pine:\n",
    "        return 15.\n",
    "    elif leading_species in species_aspen:\n",
    "        return 15.\n",
    "    else:\n",
    "        return 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipsy_exclusion = {'08':{'min_si':tipsy_minsi_tsa08, \n",
    "                         'min_vol':lambda s: 140., \n",
    "                         'excl_bec':[],\n",
    "                         'excl_leading_species':list(itertools.chain(species_aspen, \n",
    "                                                                     species_birch, \n",
    "                                                                     species_larch, \n",
    "                                                                     species_willow,\n",
    "                                                                     species_alder,\n",
    "                                                                     species_cherry,\n",
    "                                                                     species_dogwood,\n",
    "                                                                     species_oak,\n",
    "                                                                     ['SB']))},\n",
    "                   '16':{'min_si':lambda s: 5., \n",
    "                         'min_vol':lambda s: 151., \n",
    "                         'excl_bec':[],\n",
    "                         'excl_leading_species':list(itertools.chain(species_willow,\n",
    "                                                                     species_birch,\n",
    "                                                                     species_larch))},\n",
    "                   '24':{'min_si':lambda s: 5., \n",
    "                         'min_vol':lambda s: 140. if s in species_pine else 182., \n",
    "                         'excl_bec':['ICH'],\n",
    "                         'excl_leading_species':list(itertools.chain(species_hemlock,\n",
    "                                                                     species_aspen,\n",
    "                                                                     species_hemlock,\n",
    "                                                                     ['SB']))}, # plus \"non-commercial deciduous\"... whatever that means (no definition of commercial species in TSR data package)\n",
    "                   '40':{'min_si':lambda s: 5., \n",
    "                         'min_vol':lambda s: 140., \n",
    "                         'excl_bec':[],\n",
    "                         'excl_leading_species':list(itertools.chain(species_birch,\n",
    "                                                                     species_larch,\n",
    "                                                                     ['SB', 'ACT']))},\n",
    "                   '41':{'min_si':lambda s: 5., \n",
    "                         'min_vol':lambda s: 120., \n",
    "                         'excl_bec':[],\n",
    "                         'excl_leading_species':list(itertools.chain(species_cedar,\n",
    "                                                                     species_hemlock,\n",
    "                                                                     species_larch,\n",
    "                                                                     species_fir,\n",
    "                                                                     species_alder,\n",
    "                                                                     species_maple,\n",
    "                                                                     species_birch,\n",
    "                                                                     ['SB']))}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output data needed to define TIPSY AUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tipsy_params_tsa08(au_id, au_data, vdyp_out):\n",
    "    tp = {'e':{}, 'f':{}}\n",
    "    #spp_pct = {spp:data['pct'] for spp, data in au_data['species'].items()}\n",
    "    #spp_1 = list(spp_pct.keys())[0]\n",
    "    spp_1 = list(au_data['species'].keys())[0]\n",
    "    if spp_1 in species_spruce:\n",
    "        if spp_1 == 'SX': spp_1 = 'SW' # no SX in TIPSY\n",
    "        tp['e']['Density'] = 1472 \n",
    "        tp['f']['Density'] = 1416 \n",
    "        tp['e']['Util_DBH_cm'] = tp['f']['Util_DBH_cm'] = 17.5\n",
    "    elif spp_1 in species_pine:\n",
    "        tp['e']['Density'] = 1624 \n",
    "        tp['f']['Density'] = 1285 \n",
    "        tp['e']['Util_DBH_cm'] = tp['f']['Util_DBH_cm'] = 12.5\n",
    "    else:\n",
    "        assert False # only planting spruce and pine\n",
    "    #si = au_data['ss'].siteprod.median()\n",
    "    si = round(au_data['ss'].SITE_INDEX.median(), 1)\n",
    "    #cc = au_data['ss'].CROWN_CLOSURE.median() * 0.01\n",
    "    bec = au_data['ss'].BEC_ZONE_CODE.iloc[0]\n",
    "    #####################################################\n",
    "    # compile OAF1 from mean stockability from VDYP output \n",
    "    # (messy!... something about the stupid '%' symbol in the fieldname\n",
    "    #  breaks compiling tmp in a comprehension)\n",
    "    tmp = []\n",
    "    for k, v in vdyp_out.items():\n",
    "        try:\n",
    "            tmp.append(v['% Stk'].iloc[0])\n",
    "        except:\n",
    "            pass\n",
    "    oaf1 = round(np.mean(tmp) * 0.01, 2)\n",
    "    #####################################################\n",
    "    #tp['e']['AU'] = tp['f']['AU'] = au_id \n",
    "    tp['e']['AU'] = tp['e']['TBLno'] = 10000 + au_id\n",
    "    tp['f']['AU'] = tp['f']['TBLno'] = 20000 + au_id\n",
    "    tp['e']['BEC'] = tp['f']['BEC'] = bec\n",
    "    tp['e']['Proportion'] = tp['f']['Proportion'] = 1\n",
    "    tp['e']['Regen_Delay'] = 2 \n",
    "    tp['f']['Regen_Delay'] = 1 \n",
    "    tp['e']['Regen_Method'] = tp['f']['Regen_Method'] = 'P' \n",
    "    tp['e']['OAF1'] = tp['f']['OAF1'] = au_data['ss'] = oaf1 # round(0.85 + (0.15 * cc), 2)\n",
    "    tp['e']['OAF2'] = tp['f']['OAF2'] = 0.95\n",
    "    tp['e']['FIZ'] = tp['f']['FIZ'] = 'I'\n",
    "    tp['e']['SPP_1'] = tp['f']['SPP_1'] = spp_1\n",
    "    tp['e']['PCT_1'] = tp['f']['PCT_1'] = 100\n",
    "    tp['e']['SI'] = tp['f']['SI'] = si\n",
    "    tp['e']['GW_1'] = tp['f']['GW_1'] = None \n",
    "    tp['e']['GW_age_1'] = tp['f']['GW_age_1'] = None           \n",
    "    for i in range(2, 6):\n",
    "        tp['e']['SPP_%i' % i] = tp['f']['SPP_%i' % i] = None\n",
    "        tp['e']['PCT_%i' % i] = tp['f']['PCT_%i' % i] = None\n",
    "        tp['e']['GW_%i' % i] = tp['f']['GW_%i' % i] = None \n",
    "        tp['e']['GW_age_%i' % i] = tp['f']['GW_age_%i' % i] = None           \n",
    "    return tp\n",
    "\n",
    "\n",
    "def tipsy_params_tsa16(au_id, au_data, vdyp_out):\n",
    "    tp = {'e':{}, 'f':{}}\n",
    "    spp_1 = list(au_data['species'].keys())[0]\n",
    "    if spp_1 in species_aspen:\n",
    "        tp['e']['Regen_Delay'] = tp['f']['Regen_Delay'] = 1\n",
    "        tp['e']['Density'], tp['f']['Density'] = 1317, 1405\n",
    "        tp['e']['SPP_1'] = tp['f']['SPP_1'] = 'AT'\n",
    "        tp['e']['SPP_2'] = tp['f']['SPP_2'] = 'PLI'\n",
    "        tp['e']['SPP_3'] = tp['f']['SPP_3'] = 'SW'\n",
    "        tp['e']['SPP_4'] = tp['f']['SPP_4'] = 'BL'\n",
    "        tp['e']['SPP_5'] = tp['f']['SPP_5'] = None\n",
    "        tp['e']['PCT_1'], tp['f']['PCT_1'] = 45, 49\n",
    "        tp['e']['PCT_2'], tp['f']['PCT_2'] = 33, 33\n",
    "        tp['e']['PCT_3'], tp['f']['PCT_3'] = 19, 14\n",
    "        tp['e']['PCT_4'], tp['f']['PCT_4'] =  4,  4\n",
    "        tp['e']['PCT_5']= tp['f']['PCT_5'] = None\n",
    "        tp['e']['GW_1'] = tp['f']['GW_1'] = None\n",
    "        tp['e']['GW_2'], tp['f']['GW_2'] = None, 2\n",
    "        tp['e']['GW_3'], tp['f']['GW_3'] = None, 1\n",
    "        tp['e']['GW_4'] = tp['f']['GW_4'] = None\n",
    "        tp['e']['GW_5'] = tp['f']['GW_5'] = None\n",
    "        tp['e']['GW_age_1'] = tp['f']['GW_age_1'] = None\n",
    "        tp['e']['GW_age_2'], tp['f']['GW_age_2'] = None, 12 # not specified in TSR data package (12 is \"default\" says Cosmin Man)\n",
    "        tp['e']['GW_age_3'], tp['f']['GW_age_3'] = None, 12 # not specified in TSR data package (12 is \"default\" says Cosmin Man)\n",
    "        tp['e']['GW_age_4'] = tp['f']['GW_age_4'] = None\n",
    "        tp['e']['GW_age_5'] = tp['f']['GW_age_5'] = None\n",
    "        tp['e']['Util_DBH_cm'] = tp['f']['Util_DBH_cm'] = 17.5\n",
    "    elif spp_1 in species_fir:\n",
    "        tp['e']['Regen_Delay'], tp['f']['Regen_Delay'] = 2, 1\n",
    "        tp['e']['Density'], tp['f']['Density'] = 1126, 1216\n",
    "        tp['e']['SPP_1'], tp['f']['SPP_1'] = 'BL',  'SW'\n",
    "        #tp['e']['SPP_2'], tp['f']['SPP_2'] = None, None\n",
    "        #tp['e']['SPP_3'], tp['f']['SPP_3'] = None, None\n",
    "        #tp['e']['SPP_4'], tp['f']['SPP_4'] = None, None\n",
    "        tp['e']['SPP_2'], tp['f']['SPP_2'] = 'SW',  'PLI'\n",
    "        tp['e']['SPP_3'], tp['f']['SPP_3'] = 'PLI', 'BL'\n",
    "        tp['e']['SPP_4'], tp['f']['SPP_4'] = 'AT',  'AT'\n",
    "        tp['e']['SPP_5'] = tp['f']['SPP_5'] = None\n",
    "        #tp['e']['PCT_1'], tp['f']['PCT_1'] = 100, 100\n",
    "        #tp['e']['PCT_2'], tp['f']['PCT_2'] = None, None\n",
    "        #tp['e']['PCT_3'], tp['f']['PCT_3'] = None, None\n",
    "        #tp['e']['PCT_4'], tp['f']['PCT_4'] = None, None\n",
    "        tp['e']['PCT_1'], tp['f']['PCT_1'] = 53, 50\n",
    "        tp['e']['PCT_2'], tp['f']['PCT_2'] = 24, 27\n",
    "        tp['e']['PCT_3'], tp['f']['PCT_3'] = 17, 21\n",
    "        tp['e']['PCT_4'], tp['f']['PCT_4'] =  6,  2\n",
    "        tp['e']['PCT_5'] = tp['f']['PCT_5'] = None\n",
    "        tp['e']['GW_1'], tp['f']['GW_1'] = None, 4\n",
    "        tp['e']['GW_2'] = tp['f']['GW_2'] = None\n",
    "        tp['e']['GW_3'] = tp['f']['GW_3'] = None \n",
    "        tp['e']['GW_4'] = tp['f']['GW_4'] = None\n",
    "        tp['e']['GW_5'] = tp['f']['GW_5'] = None\n",
    "        tp['e']['GW_age_1'], tp['f']['GW_age_1'] = None, 12 # not specified in TSR data package (12 is \"default\" says Cosmin Man)\n",
    "        tp['e']['GW_age_2'] = tp['f']['GW_age_2'] = None\n",
    "        tp['e']['GW_age_3'] = tp['f']['GW_age_3'] = None\n",
    "        tp['e']['GW_age_4'] = tp['f']['GW_age_4'] = None\n",
    "        tp['e']['GW_age_5'] = tp['f']['GW_age_5'] = None\n",
    "        tp['e']['Util_DBH_cm'] = tp['f']['Util_DBH_cm'] = 17.5\n",
    "    elif spp_1 in species_pine:\n",
    "        tp['e']['Regen_Delay'], tp['f']['Regen_Delay'] = 2, 1\n",
    "        tp['e']['Density'], tp['f']['Density'] = 1196, 1231\n",
    "        tp['e']['SPP_1'], tp['f']['SPP_1'] = 'PLI', 'PLI'\n",
    "        #tp['e']['SPP_2'], tp['f']['SPP_2'] = 'AT',  'SW'\n",
    "        #tp['e']['SPP_3'], tp['f']['SPP_3'] = 'SW',  'AT'\n",
    "        #tp['e']['SPP_4'], tp['f']['SPP_4'] = 'BL',  'BL'\n",
    "        tp['e']['SPP_2'], tp['f']['SPP_2'] = None, None\n",
    "        tp['e']['SPP_3'], tp['f']['SPP_3'] = None, None\n",
    "        tp['e']['SPP_4'], tp['f']['SPP_4'] = None, None\n",
    "        tp['e']['SPP_5'] = tp['f']['SPP_5'] = None\n",
    "        #tp['e']['PCT_1'], tp['f']['PCT_1'] = 51, 61\n",
    "        #tp['e']['PCT_2'], tp['f']['PCT_2'] = 49, 39\n",
    "        #tp['e']['PCT_2'], tp['f']['PCT_2'] = 17, 27\n",
    "        #tp['e']['PCT_3'], tp['f']['PCT_3'] = 21,  7\n",
    "        #tp['e']['PCT_4'], tp['f']['PCT_4'] = 11,  5\n",
    "        tp['e']['PCT_1'], tp['f']['PCT_1'] = 100, 100\n",
    "        tp['e']['PCT_2'], tp['f']['PCT_2'] = None, None\n",
    "        tp['e']['PCT_3'], tp['f']['PCT_3'] = None, None\n",
    "        tp['e']['PCT_4'], tp['f']['PCT_4'] = None, None\n",
    "        tp['e']['PCT_5'] = tp['f']['PCT_5'] = None\n",
    "        tp['e']['GW_1'] = tp['f']['GW_1'] = None\n",
    "        #tp['e']['GW_2'], tp['f']['GW_2'] = None, 2\n",
    "        tp['e']['GW_2'], tp['f']['GW_2'] = None, None\n",
    "        tp['e']['GW_3'] = tp['f']['GW_3'] = None \n",
    "        tp['e']['GW_4'] = tp['f']['GW_4'] = None\n",
    "        tp['e']['GW_5'] = tp['f']['GW_5'] = None\n",
    "        tp['e']['GW_age_1'] = tp['f']['GW_age_1'] = None\n",
    "        #tp['e']['GW_age_2'], tp['f']['GW_age_2'] = None, 12 # not specified in TSR data package (12 is \"default\" says Cosmin Man)\n",
    "        tp['e']['GW_age_2'], tp['f']['GW_age_2'] = None, None\n",
    "        tp['e']['GW_age_3'] = tp['f']['GW_age_3'] = None\n",
    "        tp['e']['GW_age_4'] = tp['f']['GW_age_4'] = None\n",
    "        tp['e']['GW_age_5'] = tp['f']['GW_age_5'] = None\n",
    "        tp['e']['Util_DBH_cm'] = tp['f']['Util_DBH_cm'] = 12.5\n",
    "    elif spp_1 in species_spruce:\n",
    "        tp['e']['Regen_Delay'], tp['f']['Regen_Delay'] = 2, 1\n",
    "        tp['e']['Density'], tp['f']['Density'] = 1147, 1245\n",
    "        tp['e']['SPP_1'], tp['f']['SPP_1'] = 'SW', 'SW'\n",
    "        tp['e']['SPP_2'], tp['f']['SPP_2'] = 'BL',  'PLI'\n",
    "        tp['e']['SPP_3'], tp['f']['SPP_3'] = 'PLI',  'AT'\n",
    "        tp['e']['SPP_4'], tp['f']['SPP_4'] = 'AT',  'BL'\n",
    "        tp['e']['SPP_5'] = tp['f']['SPP_5'] = None\n",
    "        tp['e']['PCT_1'], tp['f']['PCT_1'] = 51, 43\n",
    "        tp['e']['PCT_2'], tp['f']['PCT_2'] = 19, 38\n",
    "        tp['e']['PCT_3'], tp['f']['PCT_3'] = 15, 12\n",
    "        tp['e']['PCT_4'], tp['f']['PCT_4'] = 15,  8\n",
    "        tp['e']['PCT_5'] = tp['f']['PCT_5'] = None\n",
    "        tp['e']['GW_1'] = tp['f']['GW_1'] = None\n",
    "        tp['e']['GW_2'], tp['f']['GW_2'] = None, 2\n",
    "        tp['e']['GW_3'] = tp['f']['GW_3'] = None \n",
    "        tp['e']['GW_4'] = tp['f']['GW_4'] = None\n",
    "        tp['e']['GW_5'] = tp['f']['GW_5'] = None\n",
    "        tp['e']['GW_age_1'] = tp['f']['GW_age_1'] = None\n",
    "        tp['e']['GW_age_2'], tp['f']['GW_age_2'] = None, 12 # not specified in TSR data package (12 is \"default\" says Cosmin Man)\n",
    "        tp['e']['GW_age_3'] = tp['f']['GW_age_3'] = None\n",
    "        tp['e']['GW_age_4'] = tp['f']['GW_age_4'] = None\n",
    "        tp['e']['GW_age_5'] = tp['f']['GW_age_5'] = None\n",
    "        tp['e']['Util_DBH_cm'] = tp['f']['Util_DBH_cm'] = 17.5\n",
    "    else:\n",
    "        assert False # bad leading species\n",
    "    tp['e']['AU'] = tp['e']['TBLno'] = 10000 + au_id\n",
    "    tp['f']['AU'] = tp['f']['TBLno'] = 20000 + au_id\n",
    "    #si = au_data['ss'].SITE_INDEX.median()\n",
    "    si = np.mean([df['SI'].mean() for df in vdyp_out.values()])\n",
    "    #si /= (au_data['ss'].SITE_INDEX / au_data['ss'].siteprod).median()\n",
    "    #si = au_data['ss'].siteprod.median()\n",
    "    tp['e']['SI'] = tp['f']['SI'] = round(si, 1)\n",
    "    tp['e']['BEC'] = tp['f']['BEC'] = au_data['ss'].BEC_ZONE_CODE.iloc[0]    \n",
    "    #####################################################\n",
    "    # compile OAF1 from mean stockability from VDYP output \n",
    "    # messy!... \n",
    "    # something about the stupid '%' symbol in the fieldname breaks compiling tmp in a comprehension\n",
    "    # also the hasty VDYP fixed-width text file import to DataFrame sometimes imports '% Stk' as two fieldnames (skip over broken tables with try/except)\n",
    "    tmp = []\n",
    "    for k, v in vdyp_out.items():\n",
    "        try:\n",
    "            tmp.append(v['% Stk'].iloc[0])\n",
    "        except:\n",
    "            pass\n",
    "    oaf1 = round(np.mean(tmp) * 0.01, 2)\n",
    "    #####################################################\n",
    "    tp['e']['OAF1'] = tp['f']['OAF1'] = oaf1 \n",
    "    tp['e']['OAF2'] = tp['f']['OAF2'] = 0.95\n",
    "    tp['e']['FIZ'] = tp['f']['FIZ'] = 'I'\n",
    "    tp['e']['Regen_Method'] = tp['f']['Regen_Method'] = 'P' \n",
    "    tp['e']['Proportion'] = tp['f']['Proportion'] = 1\n",
    "    \n",
    "    return tp\n",
    "\n",
    "\n",
    "def tipsy_params_tsa24(au_id, au_data, vdyp_out):\n",
    "    tp = {'e':{}, 'f':{}}\n",
    "    spp_1 = list(au_data['species'].keys())[0]\n",
    "    si = round(np.mean([df['SI'].mean() for df in vdyp_out.values()]), 1)\n",
    "    bec = au_data['ss'].BEC_ZONE_CODE.iloc[0]    \n",
    "    tp['e']['SI'] = tp['f']['SI'] = si\n",
    "    tp['e']['BEC'] = tp['f']['BEC'] = bec\n",
    "    tp['e']['AU'] = tp['e']['TBLno'] = 10000 + au_id\n",
    "    tp['f']['AU'] = tp['f']['TBLno'] = 20000 + au_id\n",
    "    #####################################################\n",
    "    # compile OAF1 from mean stockability from VDYP output \n",
    "    # messy!... \n",
    "    # something about the stupid '%' symbol in the fieldname breaks compiling tmp in a comprehension\n",
    "    # also the hasty VDYP fixed-width text file import to DataFrame sometimes imports '% Stk' as two fieldnames (skip over broken tables with try/except)\n",
    "    tmp = []\n",
    "    for k, v in vdyp_out.items():\n",
    "        try:\n",
    "            tmp.append(v['% Stk'].iloc[0])\n",
    "        except:\n",
    "            pass\n",
    "    oaf1 = round(np.mean(tmp) * 0.01, 2)\n",
    "    #####################################################\n",
    "    tp['e']['OAF1'] = tp['f']['OAF1'] = oaf1 \n",
    "    tp['e']['OAF2'] = tp['f']['OAF2'] = 0.95\n",
    "    tp['e']['FIZ'] = tp['f']['FIZ'] = 'I'\n",
    "    tp['e']['Regen_Method'] = tp['f']['Regen_Method'] = 'P' \n",
    "    tp['e']['Proportion'] = tp['f']['Proportion'] = 1\n",
    "    tp['e']['GW_3'] = tp['f']['GW_3'] = None\n",
    "    tp['e']['GW_4'] = tp['f']['GW_4'] = None\n",
    "    tp['e']['GW_5'] = tp['f']['GW_5'] = None\n",
    "    tp['e']['GW_age_3'] = tp['f']['GW_age_3'] = None\n",
    "    tp['e']['GW_age_4'] = tp['f']['GW_age_4'] = None\n",
    "    tp['e']['GW_age_5'] = tp['f']['GW_age_5'] = None\n",
    "    tp['e']['Util_DBH_cm'] = tp['f']['Util_DBH_cm'] = 17.5\n",
    "    if bec == 'SBS':\n",
    "        if spp_1 in species_pine:\n",
    "            tp['e']['Regen_Delay'] = tp['f']['Regen_Delay'] = 2\n",
    "            tp['e']['Density'], tp['f']['Density'] = 5700, 1700\n",
    "            tp['e']['Regen_Method'] = 'N' \n",
    "            tp['e']['SPP_1'], tp['f']['SPP_1'] = 'PL', 'PL'\n",
    "            tp['e']['SPP_2'], tp['f']['SPP_2'] = 'SW', 'SW'\n",
    "            tp['e']['SPP_3'], tp['f']['SPP_3'] = 'BL', None\n",
    "            tp['e']['SPP_4'], tp['f']['SPP_4'] = 'FDI', None\n",
    "            tp['e']['SPP_5'] = tp['f']['SPP_5'] = None\n",
    "            tp['e']['PCT_1'], tp['f']['PCT_1'] = 69, 67\n",
    "            tp['e']['PCT_2'], tp['f']['PCT_2'] = 13, 33\n",
    "            tp['e']['PCT_3'], tp['f']['PCT_3'] = 11, None\n",
    "            tp['e']['PCT_4'], tp['f']['PCT_4'] = 7, None\n",
    "            tp['e']['PCT_5'] = tp['f']['PCT_5'] = None\n",
    "            tp['e']['GW_1'], tp['f']['GW_1'] = None, 2\n",
    "            tp['e']['GW_2'], tp['f']['GW_2'] = None, 18\n",
    "            tp['e']['GW_age_1'], tp['f']['GW_age_1'] = None, 12 # not specified in TSR data package (12 is \"default\" says Cosmin Man)\n",
    "            tp['e']['GW_age_2'], tp['f']['GW_age_2'] = None, 12 # not specified in TSR data package (12 is \"default\" says Cosmin Man)\n",
    "        elif spp_1 in species_spruce:\n",
    "            tp['e']['Regen_Delay'] = tp['f']['Regen_Delay'] = 2\n",
    "            tp['e']['Density'], tp['f']['Density'] = 1600, 1600\n",
    "            tp['e']['SPP_1'], tp['f']['SPP_1'] = 'SW', 'SW'\n",
    "            tp['e']['SPP_2'], tp['f']['SPP_2'] = 'PL', 'PL'\n",
    "            tp['e']['SPP_3'], tp['f']['SPP_3'] = 'FDI', 'FDI'\n",
    "            tp['e']['SPP_4'], tp['f']['SPP_4'] = 'BL', None\n",
    "            tp['e']['SPP_5'] = tp['f']['SPP_5'] = None\n",
    "            tp['e']['PCT_1'], tp['f']['PCT_1'] = 55, 55\n",
    "            tp['e']['PCT_2'], tp['f']['PCT_2'] = 38, 38\n",
    "            tp['e']['PCT_3'], tp['f']['PCT_3'] =  5,  7\n",
    "            tp['e']['PCT_4'], tp['f']['PCT_4'] =  2, None\n",
    "            tp['e']['PCT_5'] = tp['f']['PCT_5'] = None\n",
    "            tp['e']['GW_1'], tp['f']['GW_1'] = 18, 18\n",
    "            tp['e']['GW_2'], tp['f']['GW_2'] = 1, 1\n",
    "            tp['e']['GW_age_1'], tp['f']['GW_age_1'] = 12, 12 # not specified in TSR data package (12 is \"default\" says Cosmin Man)\n",
    "            tp['e']['GW_age_2'], tp['f']['GW_age_2'] = 12, 12 # not specified in TSR data package (12 is \"default\" says Cosmin Man)      \n",
    "        elif spp_1 in species_cedar:\n",
    "            tp['e']['Regen_Delay'] = tp['f']['Regen_Delay'] = 2\n",
    "            tp['e']['Density'] = tp['f']['Density'] = 2200\n",
    "            tp['e']['SPP_1'] = tp['f']['SPP_1'] = 'SW'\n",
    "            tp['e']['SPP_2'] = tp['f']['SPP_2'] = 'PL'\n",
    "            tp['e']['SPP_3'] = tp['f']['SPP_3'] = 'FDI'\n",
    "            tp['e']['SPP_4'] = tp['f']['SPP_4'] = 'BL'\n",
    "            tp['e']['SPP_5'] = tp['f']['SPP_5'] = None\n",
    "            tp['e']['PCT_1'] = tp['f']['PCT_1'] = 55\n",
    "            tp['e']['PCT_2'] = tp['f']['PCT_2'] = 21\n",
    "            tp['e']['PCT_3'] = tp['f']['PCT_3'] = 16\n",
    "            tp['e']['PCT_4'] = tp['f']['PCT_4'] = 8\n",
    "            tp['e']['PCT_5'] = tp['f']['PCT_5'] = None\n",
    "            tp['e']['GW_1'] = tp['f']['GW_1'] = 21\n",
    "            tp['e']['GW_2'] = tp['f']['GW_2'] = 2\n",
    "            tp['e']['GW_age_1'] = tp['f']['GW_age_1'] = 12 # not specified in TSR data package (12 is \"default\" says Cosmin Man)\n",
    "            tp['e']['GW_age_2'] = tp['f']['GW_age_2'] = 12 # not specified in TSR data package (12 is \"default\" says Cosmin Man)                  \n",
    "        elif spp_1 in species_fir:\n",
    "            tp['e']['Regen_Delay'] = tp['f']['Regen_Delay'] = 2\n",
    "            tp['e']['Density'] = tp['f']['Density'] = 2500\n",
    "            tp['e']['SPP_1'] = tp['f']['SPP_1'] = 'SW'\n",
    "            tp['e']['SPP_2'] = tp['f']['SPP_2'] = 'PL'\n",
    "            tp['e']['SPP_3'] = tp['f']['SPP_3'] = 'BL'\n",
    "            tp['e']['SPP_4'] = tp['f']['SPP_4'] = 'FDI'\n",
    "            tp['e']['SPP_5'] = tp['f']['SPP_5'] = None\n",
    "            tp['e']['PCT_1'] = tp['f']['PCT_1'] = 57\n",
    "            tp['e']['PCT_2'] = tp['f']['PCT_2'] = 25\n",
    "            tp['e']['PCT_3'] = tp['f']['PCT_3'] = 10\n",
    "            tp['e']['PCT_4'] = tp['f']['PCT_4'] = 8\n",
    "            tp['e']['PCT_5'] = tp['f']['PCT_5'] = None\n",
    "            tp['e']['GW_1'] = tp['f']['GW_1'] = 15\n",
    "            tp['e']['GW_2'] = tp['f']['GW_2'] = 1\n",
    "            tp['e']['GW_age_1'] = tp['f']['GW_age_1'] = 12 # not specified in TSR data package (12 is \"default\" says Cosmin Man)\n",
    "            tp['e']['GW_age_2'] = tp['f']['GW_age_2'] = 12 # not specified in TSR data package (12 is \"default\" says Cosmin Man)      \n",
    "        elif spp_1 in species_douglasfir:\n",
    "            tp['e']['Regen_Delay'] = tp['f']['Regen_Delay'] = 1\n",
    "            tp['e']['Density'] = tp['f']['Density'] = 1600\n",
    "            tp['e']['SPP_1'] = tp['f']['SPP_1'] = 'FDI'\n",
    "            tp['e']['SPP_2'] = tp['f']['SPP_2'] = None\n",
    "            tp['e']['SPP_3'] = tp['f']['SPP_3'] = None\n",
    "            tp['e']['SPP_4'] = tp['f']['SPP_4'] = None\n",
    "            tp['e']['SPP_5'] = tp['f']['SPP_5'] = None\n",
    "            tp['e']['PCT_1'] = tp['f']['PCT_1'] = 100\n",
    "            tp['e']['PCT_2'] = tp['f']['PCT_2'] = None\n",
    "            tp['e']['PCT_3'] = tp['f']['PCT_3'] = None\n",
    "            tp['e']['PCT_4'] = tp['f']['PCT_4'] = None\n",
    "            tp['e']['PCT_5'] = tp['f']['PCT_5'] = None\n",
    "            tp['e']['GW_1'] = tp['f']['GW_1'] = None\n",
    "            tp['e']['GW_2'] = tp['f']['GW_2'] = None\n",
    "            tp['e']['GW_age_1'] = tp['f']['GW_age_1'] = None\n",
    "            tp['e']['GW_age_2'] = tp['f']['GW_age_2'] = None\n",
    "        else:\n",
    "            print(spp_1)\n",
    "            assert False # bad species\n",
    "    elif bec == 'ESSF':\n",
    "        if spp_1 in species_fir:\n",
    "            tp['e']['Regen_Delay'] = tp['f']['Regen_Delay'] = 1\n",
    "            tp['e']['Density'] = tp['f']['Density'] = 1500\n",
    "            tp['e']['SPP_1'] = tp['f']['SPP_1'] = 'SE'\n",
    "            tp['e']['SPP_2'] = tp['f']['SPP_2'] = 'PL'\n",
    "            tp['e']['SPP_3'] = tp['f']['SPP_3'] = 'BL'\n",
    "            tp['e']['SPP_4'] = tp['f']['SPP_4'] = None\n",
    "            tp['e']['SPP_5'] = tp['f']['SPP_5'] = None\n",
    "            tp['e']['PCT_1'] = tp['f']['PCT_1'] = 73\n",
    "            tp['e']['PCT_2'] = tp['f']['PCT_2'] = 21\n",
    "            tp['e']['PCT_3'] = tp['f']['PCT_3'] = 6\n",
    "            tp['e']['PCT_4'] = tp['f']['PCT_4'] = None\n",
    "            tp['e']['PCT_5'] = tp['f']['PCT_5'] = None\n",
    "            tp['e']['GW_1'] = tp['f']['GW_1'] = 12\n",
    "            tp['e']['GW_2'] = tp['f']['GW_2'] =  2\n",
    "            tp['e']['GW_age_1'] = tp['f']['GW_age_1'] = 12 # not specified in TSR data package (12 is \"default\" says Cosmin Man)\n",
    "            tp['e']['GW_age_2'] = tp['f']['GW_age_2'] = 12 # not specified in TSR data package (12 is \"default\" says Cosmin Man)      \n",
    "        elif spp_1 in species_spruce:\n",
    "            tp['e']['Regen_Delay'] = tp['f']['Regen_Delay'] = 1\n",
    "            tp['e']['Density'] = tp['f']['Density'] = 1500\n",
    "            tp['e']['SPP_1'] = tp['f']['SPP_1'] = 'SE'\n",
    "            tp['e']['SPP_2'] = tp['f']['SPP_2'] = 'PL'\n",
    "            tp['e']['SPP_3'] = tp['f']['SPP_3'] = 'BL'\n",
    "            tp['e']['SPP_4'] = tp['f']['SPP_4'] = None\n",
    "            tp['e']['SPP_5'] = tp['f']['SPP_5'] = None\n",
    "            tp['e']['PCT_1'] = tp['f']['PCT_1'] = 82\n",
    "            tp['e']['PCT_2'] = tp['f']['PCT_2'] = 13\n",
    "            tp['e']['PCT_3'] = tp['f']['PCT_3'] = 5\n",
    "            tp['e']['PCT_4'] = tp['f']['PCT_4'] = None\n",
    "            tp['e']['PCT_5'] = tp['f']['PCT_5'] = None\n",
    "            tp['e']['GW_1'] = tp['f']['GW_1'] = 18\n",
    "            tp['e']['GW_2'] = tp['f']['GW_2'] = 2\n",
    "            tp['e']['GW_age_1'] = tp['f']['GW_age_1'] = 12 # not specified in TSR data package (12 is \"default\" says Cosmin Man)\n",
    "            tp['e']['GW_age_2'] = tp['f']['GW_age_2'] = 12 # not specified in TSR data package (12 is \"default\" says Cosmin Man)      \n",
    "        elif spp_1 in species_pine:\n",
    "            tp['e']['Regen_Delay'] = tp['f']['Regen_Delay'] = 2\n",
    "            tp['e']['Density'] = tp['f']['Density'] = 2900\n",
    "            tp['e']['SPP_1'] = tp['f']['SPP_1'] = 'PL'\n",
    "            tp['e']['SPP_2'] = tp['f']['SPP_2'] = 'BL'\n",
    "            tp['e']['SPP_3'] = tp['f']['SPP_3'] = 'SE'\n",
    "            tp['e']['SPP_4'] = tp['f']['SPP_4'] = None\n",
    "            tp['e']['SPP_5'] = tp['f']['SPP_5'] = None\n",
    "            tp['e']['PCT_1'] = tp['f']['PCT_1'] = 62\n",
    "            tp['e']['PCT_2'] = tp['f']['PCT_2'] = 21\n",
    "            tp['e']['PCT_3'] = tp['f']['PCT_3'] = 17 \n",
    "            tp['e']['PCT_4'] = tp['f']['PCT_4'] = None\n",
    "            tp['e']['PCT_5'] = tp['f']['PCT_5'] = None\n",
    "            tp['e']['GW_1'] = tp['f']['GW_1'] = 1\n",
    "            tp['e']['GW_2'] = tp['f']['GW_2'] = 13\n",
    "            tp['e']['GW_age_1'] = tp['f']['GW_age_1'] = 12 # not specified in TSR data package (12 is \"default\" says Cosmin Man)\n",
    "            tp['e']['GW_age_2'] = tp['f']['GW_age_2'] = 12 # not specified in TSR data package (12 is \"default\" says Cosmin Man)      \n",
    "            tp['e']['Util_DBH_cm'] = tp['f']['Util_DBH_cm'] = 12.5\n",
    "        else:\n",
    "            print(spp_1)\n",
    "            assert False # bad species\n",
    "    else:\n",
    "        print(bec)\n",
    "        assert False # bad BEC zone\n",
    "    return tp\n",
    "\n",
    "\n",
    "def tipsy_params_tsa40(au_id, au_data, vdyp_out):\n",
    "    tp = {'e':{}, 'f':{}}\n",
    "    spp_1 = list(au_data['species'].keys())[0]\n",
    "    si = round(np.mean([df['SI'].mean() for df in vdyp_out.values()]), 1)\n",
    "    bec = au_data['ss'].BEC_ZONE_CODE.iloc[0]    \n",
    "    tp['e']['SI'] = tp['f']['SI'] = si\n",
    "    tp['e']['BEC'] = tp['f']['BEC'] = bec\n",
    "    tp['e']['AU'] = tp['e']['TBLno'] = 10000 + au_id\n",
    "    tp['f']['AU'] = tp['f']['TBLno'] = 20000 + au_id\n",
    "    #####################################################\n",
    "    # compile OAF1 from mean stockability from VDYP output \n",
    "    # messy!... \n",
    "    # something about the stupid '%' symbol in the fieldname breaks compiling tmp in a comprehension\n",
    "    # also the hasty VDYP fixed-width text file import to DataFrame sometimes imports '% Stk' as two fieldnames (skip over broken tables with try/except)\n",
    "    tmp = []\n",
    "    for k, v in vdyp_out.items():\n",
    "        try:\n",
    "            tmp.append(v['% Stk'].iloc[0])\n",
    "        except:\n",
    "            pass\n",
    "    oaf1 = round(np.mean(tmp) * 0.01, 2)\n",
    "    #####################################################\n",
    "    tp['e']['OAF1'] = tp['f']['OAF1'] = oaf1 \n",
    "    tp['e']['OAF2'] = tp['f']['OAF2'] = 0.95\n",
    "    tp['e']['FIZ'] = tp['f']['FIZ'] = 'I'\n",
    "    tp['e']['Regen_Method'] = tp['f']['Regen_Method'] = 'P' \n",
    "    tp['e']['Proportion'] = tp['f']['Proportion'] = 1\n",
    "    tp['e']['Util_DBH_cm'] = tp['f']['Util_DBH_cm'] = 17.5 if spp_1 not in [species_pine] else 12.5\n",
    "    spp_pct = [(spp, au_data['species'][spp]['pct']) for spp in au_data['species']]\n",
    "    #print(spp_pct)\n",
    "    for i in range(1, 6):\n",
    "        try: \n",
    "            spp, pct = spp_pct[i-1]\n",
    "            if spp == 'SX': spp = 'SW'\n",
    "        except: \n",
    "            spp = pct = None\n",
    "        for j in ['e', 'f']:\n",
    "            tp[j]['SPP_%i' % i] = spp\n",
    "            tp[j]['PCT_%i' % i] = pct\n",
    "            tp[j]['GW_%i' % i] = None\n",
    "            tp[j]['GW_age_%i' % i] = None\n",
    "\n",
    "    if bec == 'BWBS':\n",
    "        if spp_1 in species_aspen:\n",
    "            tp['e']['Regen_Delay'] = tp['f']['Regen_Delay'] = 2\n",
    "            tp['e']['Density'] = tp['f']['Density'] = 4444\n",
    "            tp['e']['Regen_Method'] = tp['f']['Regen_Method'] = 'N' # TSR data package says to use 'N', but then stands break up very early suddenly \n",
    "        elif spp_1 in species_pine:\n",
    "            tp['e']['Regen_Delay'] = tp['f']['Regen_Delay'] = 2\n",
    "            tp['e']['Density'] = tp['f']['Density'] = 1348\n",
    "            tp['e']['Regen_Method'] = tp['f']['Regen_Method'] = 'P'\n",
    "        elif spp_1 in species_spruce:\n",
    "            tp['e']['Regen_Delay'] = tp['f']['Regen_Delay'] = 1\n",
    "            tp['e']['Density'] = tp['f']['Density'] = 1167\n",
    "            tp['e']['Regen_Method'] = tp['f']['Regen_Method'] = 'P'\n",
    "        else:\n",
    "            print('bad species', spp_1)\n",
    "            assert False\n",
    "    elif bec == 'ESSF':\n",
    "        if spp_1 in species_pine:\n",
    "            tp['e']['Regen_Delay'] = tp['f']['Regen_Delay'] = 2\n",
    "            tp['e']['Density'] = tp['f']['Density'] = 1186\n",
    "            tp['e']['Regen_Method'] = tp['f']['Regen_Method'] = 'P'\n",
    "        elif spp_1 in species_spruce:\n",
    "            tp['e']['Regen_Delay'] = tp['f']['Regen_Delay'] = 1\n",
    "            tp['e']['Density'] = tp['f']['Density'] = 1070\n",
    "            tp['e']['Regen_Method'] = tp['f']['Regen_Method'] = 'P'\n",
    "        else:\n",
    "            print('bad species', spp_1)\n",
    "            assert False        \n",
    "    elif bec == 'SWB':\n",
    "        if spp_1 in species_pine:\n",
    "            tp['e']['Regen_Delay'] = tp['f']['Regen_Delay'] = 2\n",
    "            tp['e']['Density'] = tp['f']['Density'] = 1338\n",
    "            tp['e']['Regen_Method'] = tp['f']['Regen_Method'] = 'P'\n",
    "        elif spp_1 in species_spruce:\n",
    "            tp['e']['Regen_Delay'] = tp['f']['Regen_Delay'] = 2\n",
    "            tp['e']['Density'] = tp['f']['Density'] = 1338\n",
    "            tp['e']['Regen_Method'] = tp['f']['Regen_Method'] = 'P'\n",
    "        else:\n",
    "            print('bad species', spp_1)\n",
    "            assert False\n",
    "    else:\n",
    "        print('bad BEC', bec)\n",
    "        assert False\n",
    "    return tp\n",
    "\n",
    "\n",
    "def tipsy_params_tsa41(au_id, au_data, vdyp_out):\n",
    "    tp = {'e':{}, 'f':{}}\n",
    "    si = round(np.mean([df['SI'].mean() for df in vdyp_out.values()]), 1)\n",
    "    bec = au_data['ss'].BEC_ZONE_CODE.iloc[0]\n",
    "    forest_type = au_data['ss']['forest_type'].mode().iloc[0]\n",
    "    tp['e']['SI'] = tp['f']['SI'] = si\n",
    "    tp['e']['BEC'] = tp['f']['BEC'] = bec\n",
    "    tp['e']['AU'] = tp['e']['TBLno'] = 10000 + au_id\n",
    "    tp['f']['AU'] = tp['f']['TBLno'] = 20000 + au_id\n",
    "    #####################################################\n",
    "    # compile OAF1 from mean stockability from VDYP output \n",
    "    # messy!... \n",
    "    # something about the stupid '%' symbol in the fieldname breaks compiling tmp in a comprehension\n",
    "    # also the hasty VDYP fixed-width text file import to DataFrame sometimes imports '% Stk' as two fieldnames (skip over broken tables with try/except)\n",
    "    tmp = []\n",
    "    for k, v in vdyp_out.items():\n",
    "        try:\n",
    "            tmp.append(v['% Stk'].iloc[0])\n",
    "        except:\n",
    "            pass\n",
    "    oaf1 = round(np.mean(tmp) * 0.01, 2)\n",
    "    #####################################################\n",
    "    tp['e']['OAF1'] = tp['f']['OAF1'] = oaf1 \n",
    "    tp['e']['OAF2'] = tp['f']['OAF2'] = 0.95\n",
    "    tp['e']['FIZ'] = tp['f']['FIZ'] = 'I'\n",
    "    tp['e']['Regen_Delay'] = tp['f']['Regen_Delay'] = 1\n",
    "    tp['e']['Regen_Method'] = tp['f']['Regen_Method'] = 'P' \n",
    "    tp['e']['Proportion'] = tp['f']['Proportion'] = 1\n",
    "    tp['e']['SPP_5'] = tp['f']['SPP_5'] = None\n",
    "    tp['e']['PCT_5'] = tp['f']['PCT_5'] = None\n",
    "    spp_pct = [(spp, au_data['species'][spp]['pct']) for spp in au_data['species']]\n",
    "    spp_1, pct_1 = spp_pct[0]\n",
    "    for i in range(1, 6): \n",
    "        for j in ['e', 'f']:\n",
    "            tp[j]['GW_%i' % i] = tp['f']['GW_age_%i' % i] = None\n",
    "    if spp_1 in species_spruce:\n",
    "        if forest_type == 1: # pure conifer\n",
    "            tp['e']['SPP_1'] = tp['f']['SPP_1'] = 'SW'\n",
    "            tp['e']['SPP_2'] = tp['f']['SPP_2'] = 'PL'\n",
    "            tp['e']['SPP_3'] = tp['f']['SPP_3'] = 'BL'\n",
    "            tp['e']['SPP_4'] = tp['f']['SPP_4'] = 'AT'\n",
    "            tp['e']['PCT_1'] = tp['f']['PCT_1'] = 63\n",
    "            tp['e']['PCT_2'] = tp['f']['PCT_2'] = 21\n",
    "            tp['e']['PCT_3'] = tp['f']['PCT_3'] = 17 \n",
    "            tp['e']['PCT_4'] = tp['f']['PCT_4'] =  1\n",
    "            tp['e']['Regen_Delay'] = tp['f']['Regen_Delay'] = 1\n",
    "            tp['e']['Density'] = tp['f']['Density'] = 1335\n",
    "        elif forest_type == 2: # conifer mix\n",
    "            assert False \n",
    "            tp['e']['SPP_1'] = tp['f']['SPP_1'] = 'BL'\n",
    "            tp['e']['SPP_2'] = tp['f']['SPP_2'] = 'BL'\n",
    "            tp['e']['SPP_3'] = tp['f']['SPP_3'] = ''\n",
    "            tp['e']['SPP_4'] = tp['f']['SPP_4'] = 'AT'\n",
    "            tp['e']['PCT_1'] = tp['f']['PCT_1'] = 63\n",
    "            tp['e']['PCT_2'] = tp['f']['PCT_2'] = 21\n",
    "            tp['e']['PCT_3'] = tp['f']['PCT_3'] = 17 \n",
    "            tp['e']['PCT_4'] = tp['f']['PCT_4'] =  1\n",
    "            tp['e']['Regen_Delay'] = tp['f']['Regen_Delay'] = 1\n",
    "            tp['e']['Density'] = tp['f']['Density'] = 1335\n",
    "        else:\n",
    "            print(spp_pct)\n",
    "            assert False # not implemented (don't need to?)\n",
    "        tp['e']['Util_DBH_cm'] = tp['f']['Util_DBH_cm'] = 17.5\n",
    "    elif spp_1 in species_fir:\n",
    "        if forest_type == 1: # pure conifer\n",
    "            tp['e']['SPP_1'] = tp['f']['SPP_1'] = 'SW'\n",
    "            tp['e']['SPP_2'] = tp['f']['SPP_2'] = 'BL'\n",
    "            tp['e']['SPP_3'] = tp['f']['SPP_3'] = 'PL'\n",
    "            tp['e']['SPP_4'] = tp['f']['SPP_4'] = 'AT'\n",
    "            tp['e']['PCT_1'] = tp['f']['PCT_1'] = 64\n",
    "            tp['e']['PCT_2'] = tp['f']['PCT_2'] = 29\n",
    "            tp['e']['PCT_3'] = tp['f']['PCT_3'] =  6 \n",
    "            tp['e']['PCT_4'] = tp['f']['PCT_4'] =  1\n",
    "            tp['e']['Density'] = tp['f']['Density'] = 1064\n",
    "        else:\n",
    "            assert False # not implemented (don't need to?)\n",
    "        tp['e']['Util_DBH_cm'] = tp['f']['Util_DBH_cm'] = 17.5\n",
    "    elif spp_1 in species_pine:\n",
    "        if forest_type == 1: # pure conifer\n",
    "            tp['e']['SPP_1'] = tp['f']['SPP_1'] = 'PL'\n",
    "            tp['e']['SPP_2'] = tp['f']['SPP_2'] = 'SW'\n",
    "            tp['e']['SPP_3'] = tp['f']['SPP_3'] = 'BL'\n",
    "            tp['e']['SPP_4'] = tp['f']['SPP_4'] = 'AT'\n",
    "            tp['e']['PCT_1'] = tp['f']['PCT_1'] = 63\n",
    "            tp['e']['PCT_2'] = tp['f']['PCT_2'] = 27\n",
    "            tp['e']['PCT_3'] = tp['f']['PCT_3'] =  8 \n",
    "            tp['e']['PCT_4'] = tp['f']['PCT_4'] =  2\n",
    "            tp['e']['Density'] = tp['f']['Density'] = 1219\n",
    "        else:\n",
    "            assert False # not implemented (don't need to?)\n",
    "        tp['e']['Util_DBH_cm'] = tp['f']['Util_DBH_cm'] = 12.5\n",
    "    elif spp_1 in species_aspen:\n",
    "        if forest_type == 4: # pure conifer\n",
    "            tp['e']['SPP_1'] = tp['f']['SPP_1'] = 'AT'\n",
    "            tp['e']['SPP_2'] = tp['f']['SPP_2'] = None\n",
    "            tp['e']['SPP_3'] = tp['f']['SPP_3'] = None\n",
    "            tp['e']['SPP_4'] = tp['f']['SPP_4'] = None\n",
    "            tp['e']['PCT_1'] = tp['f']['PCT_1'] = 100\n",
    "            tp['e']['PCT_2'] = tp['f']['PCT_2'] = None\n",
    "            tp['e']['PCT_3'] = tp['f']['PCT_3'] = None \n",
    "            tp['e']['PCT_4'] = tp['f']['PCT_4'] = None\n",
    "            tp['e']['Density'] = tp['f']['Density'] = 3134\n",
    "            tp['e']['Regen_Method'] = tp['f']['Regen_Method'] = 'N' \n",
    "        else:\n",
    "            assert False # not implemented (don't need to?)\n",
    "        tp['e']['Util_DBH_cm'] = tp['f']['Util_DBH_cm'] = 12.5\n",
    "    else:\n",
    "        print('bad species', spp_1)\n",
    "        assert False\n",
    "    return tp\n",
    "\n",
    "\n",
    "\n",
    "#for i, spp in enumerate(spp_pct, start=1):\n",
    "#    tp['e']['spp_%i' % i] = tp['f']['spp_%i' % i] = spp\n",
    "#    tp['e']['pct_%i' % i] = tp['f']['pct_%i' % i] = spp_pct[spp]\n",
    "#    tp['e']['gw_%i' % i] = tp['f']['gw_%i' % i] = None \n",
    "#    tp['e']['gw_age_%i' % i] = tp['f']['gw_age_%i' % i] = None \n",
    "#for i in range(i, 5):\n",
    "#    tp['e']['spp_%i' % i] = tp['f']['spp_%i' % i] = None\n",
    "#    tp['e']['pct_%i' % i] = tp['f']['pct_%i' % i] = None\n",
    "#    tp['e']['gw_%i' % i] = tp['f']['gw_%i' % i] = None \n",
    "#    tp['e']['gw_age_%i' % i] = tp['f']['gw_age_%i' % i] = None           \n",
    "\n",
    "\n",
    "    \n",
    "tipsy_params_dispatch = {'08':tipsy_params_tsa08,\n",
    "                         '16':tipsy_params_tsa16,\n",
    "                         '24':tipsy_params_tsa24,\n",
    "                         '40':tipsy_params_tsa40,\n",
    "                         '41':tipsy_params_tsa41}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_operable_years = 50\n",
    "verbose = 1\n",
    "si_iqrlo_quantile = 0.50\n",
    "scsi_au[tsa] = {}\n",
    "au_scsi[tsa] = {}\n",
    "tipsy_params[tsa] = {}\n",
    "#for i in range(30):\n",
    "for stratumi, sc, result in results[tsa]:\n",
    "    print(sc)\n",
    "    for i, si_level in enumerate(si_levels, start=1):\n",
    "        au = 1000*i + stratumi\n",
    "        scsi_au[tsa][(sc, si_level)] = au\n",
    "        au_scsi[tsa][au] = (sc, si_level)\n",
    "        te = tipsy_exclusion[tsa]\n",
    "        df = vdyp_curves_smooth[tsa].set_index(['stratum_code', 'si_level']).loc[sc, si_level]\n",
    "        max_vol = df.volume.max()\n",
    "        min_vol = te['min_vol'](sc.split('_')[1][0])\n",
    "        if max_vol < min_vol:\n",
    "            if verbose:\n",
    "                print('  ', si_level, 'max_vol too low', max_vol, te['min_vol'])\n",
    "            continue\n",
    "        operable_ages = df[df.volume >= min_vol].age\n",
    "        operable_years = operable_ages.max() - operable_ages.min()\n",
    "        if operable_years < min_operable_years:\n",
    "            if verbose:\n",
    "                print('  ', si_level, 'operability window too narrow', operable_years, min_operable_years)\n",
    "            continue\n",
    "        try:\n",
    "            si_vri_iqrlo = result[si_level]['ss'].SITE_INDEX.quantile(si_iqrlo_quantile)\n",
    "        except:\n",
    "            print(sc, si_level)\n",
    "            print(result[si_level]['ss'])\n",
    "            assert False\n",
    "        si_spr_iqrlo = result[si_level]['ss'].siteprod.quantile(si_iqrlo_quantile)\n",
    "        si_vri_med = result[si_level]['ss'].SITE_INDEX.median()\n",
    "        si_spr_med = result[si_level]['ss'].siteprod.median()\n",
    "        leading_species = list(result[si_level]['species'].keys())[0]\n",
    "        min_si = te['min_si'](leading_species)\n",
    "        if min(si_vri_iqrlo, si_spr_iqrlo) < min_si:\n",
    "            if verbose:\n",
    "                print('  ', si_level, 'SI too low (using %0.2f quantile)' % si_iqrlo_quantile, \n",
    "                      '%2.1f' % si_vri_iqrlo, '%2.1f' % si_spr_iqrlo, min_si)\n",
    "            continue\n",
    "        if leading_species in te['excl_leading_species']:\n",
    "            if verbose:\n",
    "                print('  ', si_level, 'bad leading species', leading_species)\n",
    "            continue\n",
    "        bec = sc.split('_')[0]\n",
    "        if bec in te['excl_bec']:\n",
    "            if verbose:\n",
    "                print('  ', si_level, 'bad bec', bec)\n",
    "            continue\n",
    "\n",
    "        print('  ', si_level, au)\n",
    "        print('    median SI (VRI)               ', ('%2.1f' % si_vri_med).rjust(4))\n",
    "        print('    median SI (siteprod)          ', ('%2.1f' % si_spr_med).rjust(4))\n",
    "        print('    median SI ratio (VRI/siteprod) ', '%0.2f' % (si_vri_med / si_spr_med))\n",
    "        for species, v in result[si_level]['species'].items():\n",
    "            print('    species', species.ljust(3), '%3.0f' % v['pct'])\n",
    "            #print('  ', si_level, '   :', '%3.0f' % max_volume, ('%2.1f' % si).rjust(4))\n",
    "            #for species, v in result[si_level]['species'].items():\n",
    "            #    print('   ', species.ljust(3), ':', '%3.0f' % v['pct'])\n",
    "        tipsy_params[tsa][au] = tipsy_params_dispatch[tsa](au, result[si_level], vdyp_results[tsa][stratumi][si_level])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    tipsy_params_ = []\n",
    "    for tsa in tipsy_params:\n",
    "        for au in tipsy_params[tsa]:\n",
    "            print(tsa, au)\n",
    "            tp = tipsy_params[tsa][au]\n",
    "            tipsy_params_.append(pd.DataFrame(tp['e'], index=[tp['e']['TBLno']]))\n",
    "            tipsy_params_.append(pd.DataFrame(tp['f'], index=[tp['f']['TBLno']]))\n",
    "        df = pd.concat(tipsy_params_)[tipsy_params_columns]\n",
    "        df.to_excel('%s%s.xlsx' % (tipsy_params_path_prefix, tsa), index=False, sheet_name='TIPSY_inputTBL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipsy_params_ = []\n",
    "for au in tipsy_params[tsa]:\n",
    "    tp = tipsy_params[tsa][au]\n",
    "    #tipsy_params_.append(pd.DataFrame(tp['e'], index=[tp['e']['TBLno']]))\n",
    "    tipsy_params_.append(pd.DataFrame(tp['f'], index=[tp['f']['TBLno']]))\n",
    "df = pd.concat(tipsy_params_)[tipsy_params_columns]\n",
    "df.to_excel('%s%s.xlsx' % (tipsy_params_path_prefix, tsa), index=False, sheet_name='TIPSY_inputTBL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('').to_string('./data/02_input-tsa%s.dat' % tsa, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pause running notebook and head to a Windows machine to run `02_input-tsa*.dat` through BatchTIPSY, then copy `04_output-tsa*.out` to `./data/` and run notebook `01_run-tsa_step2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
